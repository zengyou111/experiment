{
    "classifiers": {
        "MLP": {
            "accuracy": 0.9857142857142858,
            "f1_score": 0.9857819905213271,
            "recall": 0.9904761904761905,
            "precision": 0.9811320754716981,
            "auc": 0.9989342403628119
        },
        "GRU": {
            "accuracy": 0.9845238095238096,
            "f1_score": 0.9846153846153846,
            "recall": 0.9904761904761905,
            "precision": 0.9788235294117648,
            "auc": 0.9988605442176871
        },
        "CNN": {
            "accuracy": 0.9797619047619047,
            "f1_score": 0.9800703399765535,
            "recall": 0.9952380952380953,
            "precision": 0.9653579676674365,
            "auc": 0.9992517006802721
        },
        "LSTM": {
            "accuracy": 0.986904761904762,
            "f1_score": 0.9869513641755634,
            "recall": 0.9904761904761905,
            "precision": 0.983451536643026,
            "auc": 0.998985260770975
        },
        "BiLSTM": {
            "accuracy": 0.986904761904762,
            "f1_score": 0.9869513641755634,
            "recall": 0.9904761904761905,
            "precision": 0.983451536643026,
            "auc": 0.9990702947845805
        },
        "RNN": {
            "accuracy": 0.9845238095238096,
            "f1_score": 0.9846153846153846,
            "recall": 0.9904761904761905,
            "precision": 0.9788235294117648,
            "auc": 0.9987585034013605
        },
        "ResNet": {
            "accuracy": 0.9821428571428571,
            "f1_score": 0.9822904368358913,
            "recall": 0.9904761904761905,
            "precision": 0.9742388758782201,
            "auc": 0.9986904761904762
        }
    },
    "ablation_study": {
        "ConbaNoControl": {
            "accuracy": 0.9857142857142858,
            "f1_score": 0.9857819905213271,
            "recall": 0.9904761904761905,
            "precision": 0.9811320754716981,
            "auc": 0.999030612244898
        },
        "ConbaNoFeedback": {
            "accuracy": 0.9845238095238096,
            "f1_score": 0.9846153846153846,
            "recall": 0.9904761904761905,
            "precision": 0.9788235294117648,
            "auc": 0.9984693877551021
        },
        "ConbaNoState": {
            "accuracy": 0.986904761904762,
            "f1_score": 0.9869513641755634,
            "recall": 0.9904761904761905,
            "precision": 0.983451536643026,
            "auc": 0.99952947845805
        },
        "Full Model": {
            "accuracy": 0.986904761904762,
            "f1_score": 0.9869513641755634,
            "recall": 0.9904761904761905,
            "precision": 0.983451536643026,
            "auc": 0.998985260770975
        }
    }
}